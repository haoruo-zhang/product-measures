{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sympy as sp\n",
    "import jax.numpy as jaxnp\n",
    "import jax.numpy as jnp\n",
    "from scipy.integrate import quad\n",
    "from scipy.optimize import minimize\n",
    "from functools import partial\n",
    "import jax\n",
    "\n",
    "def g_D_symbolic_coefficients(x,polynomial):\n",
    "    \"\"\"\n",
    "    x is using to define polynomial\n",
    "    \"\"\"\n",
    "  \n",
    "    # Expand the result\n",
    "    expanded_result = sp.expand(polynomial)\n",
    "    \n",
    "    # Initialize a dict to store coefficients\n",
    "    coefficients_dict = {}\n",
    "    \n",
    "    # Get all terms in the expanded result\n",
    "    terms = expanded_result.as_ordered_terms()\n",
    "    \n",
    "    for term in terms:\n",
    "        variables_powers = sp.Poly(term, x).as_dict()\n",
    "        for vars_tuple, coeff in variables_powers.items():\n",
    "            # Convert SymPy coefficients to float to be compatible with JAX\n",
    "            coefficients_dict[vars_tuple] = float(coeff)\n",
    "    \n",
    "    # Convert the SymPy expression into a numerical function compatible with JAX\n",
    "    polynomial_numeric = sp.lambdify(x, polynomial, 'numpy')\n",
    "    print(\"Expanded Result:\")\n",
    "    print(expanded_result)\n",
    "    print(\"\\nCoefficients Dictionary:\")\n",
    "    for vars_tuple, coeff in coefficients_dict.items():\n",
    "        print(f\"Coefficient of {vars_tuple}: {coeff}\")\n",
    "\n",
    "    orders_list = list(coefficients_dict.keys())\n",
    "    coefficients_list = list(coefficients_dict.values())\n",
    "    print(orders_list)\n",
    "    print(coefficients_list)\n",
    "    return orders_list, coefficients_list, polynomial_numeric, x\n",
    "\n",
    "def restore_matrices(s,d,D,L):\n",
    "    \"\"\"\n",
    "    s is the flattend x\n",
    "    d is the highest order of polynomial\n",
    "    D is the number of variables in polynomial\n",
    "    L is the number of measures\n",
    "    \"\"\"\n",
    "\n",
    "    # Define matrix dimensions\n",
    "    md_shape = (2*d+1,)\n",
    "    Rd_shape = (d+1,d+1)\n",
    "\n",
    "    # Initialize empty lists to store the restored matrices\n",
    "    x_mu_D_L_list = [[] for _ in range(D)]\n",
    "    x_R_L_list = [[] for _ in range(D)]\n",
    "    \n",
    "    # Set the initial index\n",
    "    start_index = 0\n",
    "\n",
    "    for i in range(D):\n",
    "        for _ in range(L):\n",
    "            # Restore list of moments of measure\n",
    "            x_mu_D_L_list[i].append(s[start_index:start_index + 2*d+1].reshape(md_shape))\n",
    "            start_index += 2*d+1\n",
    "    \n",
    "\n",
    "    for i in range(D):\n",
    "        for _ in range(L):\n",
    "            # Restore R_i(d) matrices\n",
    "            x_R_L_list[i].append(s[start_index:start_index + (d+1)**2].reshape(Rd_shape))\n",
    "            start_index += (d+1)**2\n",
    "    x_mu_D_L_list = jnp.array(x_mu_D_L_list)\n",
    "    x_R_L_list = jnp.array(x_R_L_list)\n",
    "    return x_mu_D_L_list,x_R_L_list\n",
    "\n",
    "#Def the function generting M_d matrix from mu list\n",
    "def generate_M_d(x_mu_D_L_list,d,D,L):\n",
    "    \"\"\"\n",
    "    Since mu list has this shape (D,L,2d+1), we need to reshape it to (D,L,d+1,d+1)\n",
    "    \"\"\"\n",
    "    x_M_D_L_list = [[] for _ in range(D)]\n",
    "    for l in range(L):\n",
    "        for q in range(D):\n",
    "            indices = jnp.arange(d + 1)\n",
    "            i, j = jnp.meshgrid(indices, indices, indexing='ij')\n",
    "            M_D_L_matrix = x_mu_D_L_list[q][l][i + j]\n",
    "            x_M_D_L_list[q].append(M_D_L_matrix)\n",
    "    return jnp.array(x_M_D_L_list)\n",
    "\n",
    "\n",
    "def Augmented_Lagrangian(x_input,d,D,L,orders_list,coefficients_list,Lagrangian_coefficient,gamma):\n",
    "    \"\"\"\n",
    "    x is the flattend x\n",
    "    D is the number of variables in polynomial\n",
    "    L is the number of measures\n",
    "    orders_list is the list of different terms(e.g. x1^2*x2^2) in polynomials\n",
    "    coefficients_list is the list of coefficients of the above terms\n",
    "    Lagrangian_coefficient is Lagrangian coefficient\n",
    "    gamma is the penalty term \n",
    "\n",
    "    \"\"\"\n",
    "    #Before we start, we need to reshape the x input back to the original format, which is the matrix form\n",
    "\n",
    "    x_mu_D_L_list,x_R_L_list = restore_matrices(s=x_input,d=d,D=D,L=L)\n",
    "    \n",
    "    sum_result = 0\n",
    "\n",
    "    #First term\n",
    "    sum_result += term_1(D,L,x_mu_D_L_list,orders_list,coefficients_list)\n",
    "\n",
    "    # #Here we need to generate the real M_d matrix from our list of moments of measure\n",
    "\n",
    "    x_M_D_L_list = generate_M_d(x_mu_D_L_list,d,D,L)\n",
    "\n",
    "    # #Second term\n",
    "    sum_result += term_2(D,L,x_M_D_L_list,x_mu_D_L_list,x_R_L_list,Lagrangian_coefficient)\n",
    "    \n",
    "    # #Third term\n",
    "    sum_result += gamma/2*term_3(D,L,x_M_D_L_list,x_mu_D_L_list,x_R_L_list)\n",
    "    return sum_result\n",
    "\n",
    "def Augmented_Lagrangian_without_objective(x_input,d,D,L,Lagrangian_coefficient,gamma):\n",
    "    \"\"\"\n",
    "    x is the flattend x\n",
    "    D is the number of variables in polynomial\n",
    "    L is the number of measures\n",
    "    orders_list is the list of different terms(e.g. x1^2*x2^2) in polynomials\n",
    "    coefficients_list is the list of coefficients of the above terms\n",
    "    Lagrangian_coefficient is Lagrangian coefficient\n",
    "    gamma is the penalty term \n",
    "\n",
    "    \"\"\"\n",
    "    #Before we start, we need to reshape the x input back to the original format, which is the matrix form\n",
    "\n",
    "    x_mu_D_L_list,x_R_L_list = restore_matrices(s=x_input,d=d,D=D,L=L)\n",
    "    \n",
    "    sum_result = 0\n",
    "    # #Here we need to generate the real M_d matrix from our list of moments of measure\n",
    "\n",
    "    x_M_D_L_list = generate_M_d(x_mu_D_L_list,d,D,L)\n",
    "\n",
    "    # #Second term\n",
    "    sum_result += term_2(D,L,x_M_D_L_list,x_mu_D_L_list,x_R_L_list,Lagrangian_coefficient)\n",
    "    \n",
    "    # #Third term\n",
    "    sum_result += gamma/2*term_3(D,L,x_M_D_L_list,x_mu_D_L_list,x_R_L_list)\n",
    "    return sum_result\n",
    "\n",
    "#This is the sum of the polynomials\n",
    "def term_1(D,L,x_mu_D_L_list,orders_list,coefficients_list):\n",
    "    sum = 0\n",
    "    for i in range(len(orders_list)):\n",
    "        moments_product_sum = 0\n",
    "        for l in range(L):\n",
    "            moments_prodect = 1\n",
    "            for j in range(D):\n",
    "                moments_prodect *= x_mu_D_L_list[j][l][orders_list[i][j]]\n",
    "            moments_product_sum += moments_prodect\n",
    "        sum +=coefficients_list[i]*moments_product_sum\n",
    "    return sum\n",
    "\n",
    "#Lagrangian term\n",
    "def term_2(D,L,x_M_D_L_list,x_mu_D_L_list,x_R_L_list,Lagrangian_coefficient):\n",
    "    \n",
    "    sum = 0\n",
    "    # Md(mu_0^(l)) - R_0^l R_0^l.T = 0\n",
    "    for i in range(D):\n",
    "        for l in range(L):\n",
    "            sum += jaxnp.sum(Lagrangian_coefficient[0][i][l]*(x_M_D_L_list[i][l]-jaxnp.dot(x_R_L_list[i][l],x_R_L_list[i][l].T)))\n",
    "    \n",
    "\n",
    "    # mu_(1,0)^l>=0\n",
    "    for l in range(L):\n",
    "        sum += Lagrangian_coefficient[1][0][l]*jaxnp.maximum(-x_M_D_L_list[0][l][0,0],0)\n",
    "    \n",
    "    # mu_(i,0)^l - 1 = 0\n",
    "    for i in range(D-1):\n",
    "        for l in range(L):\n",
    "            sum += Lagrangian_coefficient[1][i+1][l]*(x_M_D_L_list[i+1][l][0,0]-1)\n",
    "    \n",
    "    #8 B.2.1.\n",
    "    for i in range(D):\n",
    "        for l in range(L):\n",
    "            sum+= jaxnp.sum(Lagrangian_coefficient[2][i][l]*(jaxnp.maximum(0,-x_mu_D_L_list[i][l]-1)+jaxnp.maximum(0,x_mu_D_L_list[i][l]-1)))\n",
    "    \n",
    "    return sum\n",
    "\n",
    "#Penanlty term\n",
    "def term_3(D,L,x_M_D_L_list,x_mu_D_L_list,x_R_L_list):\n",
    "    sum = 0 \n",
    "    # Md(mu_0^(l)) - R_0^l R_0^l.T = 0\n",
    "    for i in range(D):\n",
    "        for l in range(L):\n",
    "            sum += jaxnp.sum(jaxnp.square((x_M_D_L_list[i][l]-jaxnp.dot(x_R_L_list[i][l],x_R_L_list[i][l].T))))\n",
    "       \n",
    "    # mu_(1,0)^l>=0 \n",
    "    # here we define the penalty term as max(0, -g)**2 since we need to let it >=0 \n",
    "    for l in range(L):\n",
    "        sum += max(0,-x_M_D_L_list[0][l][0,0])**2\n",
    "    \n",
    "    # mu_(i,0)^l - 1 = 0\n",
    "    for i in range(D-1):\n",
    "        for l in range(L):\n",
    "            sum += (x_M_D_L_list[i+1][l][0,0]-1)**2\n",
    "\n",
    "       \n",
    "    # B.2.1.\n",
    "    for i in range(D):\n",
    "        for l in range(L):\n",
    "            sum+= jaxnp.sum(jaxnp.square(jaxnp.maximum(0,-x_mu_D_L_list[i][l]-1)+jaxnp.maximum(0,x_mu_D_L_list[i][l]-1)))\n",
    "    \n",
    "    return sum\n",
    "\n",
    "def update_Lagrangian_coefficients(d,D,L,x_input,Lagrangian_coefficient,gamma):\n",
    "    \"\"\"\n",
    "    D is the number of variables in polynomial\n",
    "    L is the number of measures\n",
    "    x_input is the flattend x\n",
    "    Lagrangian_coefficient is Lagrangian coefficient\n",
    "    gamma is the penalty term \n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    #Before we start, we need to reshape the x input back to the original format\n",
    "    x_mu_D_L_list,x_R_L_list = restore_matrices(s=x_input,d=d,D=D,L=L)\n",
    "    x_M_D_L_list = generate_M_d(x_mu_D_L_list,d,D,L)\n",
    "\n",
    "    # 1.Md(mu_0^(l)) - R_0^l R_0^l.T = 0\n",
    "    for i in range(D):\n",
    "        for l in range(L):\n",
    "            Lagrangian_coefficient[0][i][l] += gamma*(x_M_D_L_list[i][l]-np.dot(x_R_L_list[i][l],x_R_L_list[i][l].T))\n",
    "    \n",
    "    # 5. mu_(1,0)^l>=0\n",
    "    for l in range(L):\n",
    "        Lagrangian_coefficient[1][0][l] += gamma*max(-x_M_D_L_list[0][l][0,0],0)\n",
    "    \n",
    "    # 6. mu_(i,0)^l - 1 = 0\n",
    "    for i in range(D-1):\n",
    "        for l in range(L):\n",
    "            Lagrangian_coefficient[1][i+1][l] += gamma*(x_M_D_L_list[i+1][l][0,0]-1)\n",
    "\n",
    "    #8 B.2.1.\n",
    "    for i in range(D):\n",
    "        for l in range(L):\n",
    "            Lagrangian_coefficient[2][i][l] += gamma*(np.maximum(0,-x_mu_D_L_list[i][l]-1)+np.maximum(0,x_mu_D_L_list[i][l]-1))\n",
    "\n",
    "    return Lagrangian_coefficient\n",
    "\n",
    "def f(x,n):\n",
    "    return 1/2*x**n\n",
    "\n",
    "def generate_x_input_p2(D,d,L):\n",
    "    \"\"\"\n",
    "    function to initialize the x_input using uniform distribution on [-1,1]\n",
    "    \"\"\"\n",
    "    x_mu_D_L_list = [[] for _ in range(D)]\n",
    "    x_R_L_list = [[] for _ in range(D)]\n",
    "\n",
    "    # 9/28 update, we first generate a list of different moments of measure, then in the augumented lagrangian, we can generate the M_d matrix from our list of moments of measure\n",
    "    # This can fix the problem that when we try to differentiate the ϕn(µ), it actully differentiate the list of moments of measure not the M_d matrix \n",
    "\n",
    "    # Define the mu_list\n",
    "    list_size = 2*d+1\n",
    "    x = sp.Symbol('x')\n",
    "    my_list = np.array([quad(f,-1,1,args=(i))[0] for i in range(list_size)])\n",
    "    del x\n",
    "    # # generate the list of list of both matrix\n",
    "    for l in range(L):\n",
    "        for i in range(D):\n",
    "            x_mu_D_L_list[i].append(my_list)\n",
    "            x_R_L_list[i].append(np.random.uniform(-1, 1, size=(d+1, d+1)))\n",
    "\n",
    "    x_matrix_list_new = x_mu_D_L_list+x_R_L_list\n",
    "    x_input = np.array([])\n",
    "    for matrix_index in range(len(x_matrix_list_new)):\n",
    "        for l in range(L):\n",
    "            flattened_array = x_matrix_list_new[matrix_index][l].flatten()\n",
    "            x_input = np.concatenate((x_input, flattened_array))\n",
    "    x_input = jnp.array(np.array(x_input.tolist(),dtype=np.float64))\n",
    "    return x_input\n",
    "\n",
    "def generate_lag(D,d,L):\n",
    "    \"\"\"\n",
    "    generate the lagrangian coefficients, we initialize them as 0\n",
    "    \"\"\"\n",
    "    Lagrangian_coefficient = [[[] for _ in range(D)],[[] for _ in range(D)],[[] for _ in range(D)]]\n",
    "\n",
    "    for l in range(L):\n",
    "        for i in range(D):\n",
    "            Lagrangian_coefficient[0][i].append(np.zeros((d+1,d+1)))\n",
    "\n",
    "    for l in range(L):\n",
    "        for i in range(D):\n",
    "            Lagrangian_coefficient[1][i].append(0)\n",
    "\n",
    "\n",
    "    for l in range(L):\n",
    "        for i in range(D):\n",
    "            Lagrangian_coefficient[2][i].append(np.zeros(2*d+1))\n",
    "        \n",
    "    return Lagrangian_coefficient\n",
    "\n",
    "\n",
    "def update_everything(x_input,gamma,Lagrangian_coefficient,v,d,D,L):\n",
    "    \"\"\"\n",
    "    This is the update of lagrangian coefficient and the penalty coefficient\n",
    "    Using the method in <A nonlinear programming algorithm for solving semidefinite programs via low-rank factorization> page 337-338\n",
    "    \"\"\"\n",
    "    x_mu_D_L_list,x_R_L_list = restore_matrices(s=x_input,d=d,D=D,L=L)\n",
    "    x_M_D_L_list = generate_M_d(x_mu_D_L_list,d,D,L)\n",
    "    v_k = term_3(D,L,x_M_D_L_list,x_mu_D_L_list,x_R_L_list)\n",
    "\n",
    "    eta = 1/4\n",
    "    rho = 10\n",
    "\n",
    "    if v_k<eta*v:\n",
    "        Lagrangian_coefficient = update_Lagrangian_coefficients(d,D,L,x_input,Lagrangian_coefficient,gamma)\n",
    "        v_k_1 = v_k\n",
    "        print(\"keep gamma, update Lagrangian\")\n",
    "    else:\n",
    "        Lagrangian_coefficient = Lagrangian_coefficient\n",
    "        gamma = gamma*rho\n",
    "        v_k_1 = v\n",
    "        print(\"keep Lagrangian, update gamma\")\n",
    "    return Lagrangian_coefficient,gamma,v_k_1\n",
    "\n",
    "def jac_term1_new(x_input, d, D, L, orders_list, coefficients_list):\n",
    "    \"\"\"\n",
    "    Optimized version of the jac_term1_new function with index handling fixed.\n",
    "    \"\"\"\n",
    "    jacobian_final = np.zeros(len(x_input))\n",
    "    x_mu_D_L_list, _ = restore_matrices(x_input, d, D, L)\n",
    "    jacobian_list = np.zeros(D * L * (2 * d + 1))\n",
    "    coefficients_list = np.array(coefficients_list)\n",
    "    # Precompute a mask for orders_list to avoid repeated condition checks\n",
    "    orders_mask = np.array([[o[x] for x in range(D)] for o in orders_list])\n",
    "    index = -1\n",
    "    for x in range(D):\n",
    "        for l in range(L):\n",
    "            for i in range(2 * d + 1):\n",
    "                index += 1\n",
    "                if i <= d:\n",
    "                    # Find terms where orders_list[o][x] == i in a vectorized way\n",
    "                    relevant_terms = np.where(orders_mask[:, x] == i)[0]\n",
    "                    if len(relevant_terms) == 0:\n",
    "                        continue\n",
    "                    \n",
    "                    # Initialize moments_product_list with ones for the relevant terms\n",
    "                    moments_product_list = np.ones(len(relevant_terms), dtype=float)\n",
    "                    # Vectorized computation of moments_product\n",
    "                    for p in range(D):\n",
    "                        if p != x:\n",
    "                            # Ensure proper integer indexing\n",
    "                            selected_orders = orders_mask[relevant_terms, p]\n",
    "                            moments_product_list *= x_mu_D_L_list[p][l][selected_orders]\n",
    "                    jacobian_matrix_sum = np.sum(coefficients_list[relevant_terms] * moments_product_list)\n",
    "                    jacobian_list[index] = jacobian_matrix_sum\n",
    "    \n",
    "    jacobian_final[:len(jacobian_list)] = jacobian_list\n",
    "    return jacobian_final\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 2\n",
    "d = 4\n",
    "L = 1\n",
    "gamma = 1000\n",
    "target_value = 0\n",
    "target_relative_error = 1e-5\n",
    "gtol = 1e-6\n",
    "ftol = 1e-6\n",
    "maxcor = 20\n",
    "x = sp.symbols(f'x1:{D+1}')\n",
    "# polynomial = sum(xi**2 for xi in x)\n",
    "xxT = sp.Matrix(x) * sp.Matrix(x).T\n",
    "# # 构造全 1 的矩阵 J，乘以 1/2\n",
    "J = sp.Matrix([[1/2] * D] * D)\n",
    "# # 计算目标函数，即 Frobenius 范数的平方\n",
    "objective_matrix = (xxT - J).applyfunc(lambda x: x**2)\n",
    "# polynomial = sum(xi**2 for xi in x)\n",
    "polynomial = sum(objective_matrix)\n",
    "polynomial = (1 / D) * sum(8 * x_i**4 - 8 * x_i**2 + 1 for x_i in x) + (sum(x) / D) ** 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0*x1**4 - 4.0*x1**2 + 4.0*x2**4 - 4.0*x2**2 + (x1/2 + x2/2)**3 + 1.0\n"
     ]
    }
   ],
   "source": [
    "print(polynomial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expanded Result:\n",
      "4.0*x1**4 + x1**3/8 + 3*x1**2*x2/8 - 4.0*x1**2 + 3*x1*x2**2/8 + 4.0*x2**4 + x2**3/8 - 4.0*x2**2 + 1.0\n",
      "\n",
      "Coefficients Dictionary:\n",
      "Coefficient of (4, 0): 4.0\n",
      "Coefficient of (3, 0): 0.125\n",
      "Coefficient of (2, 1): 0.375\n",
      "Coefficient of (2, 0): -4.0\n",
      "Coefficient of (1, 2): 0.375\n",
      "Coefficient of (0, 4): 4.0\n",
      "Coefficient of (0, 3): 0.125\n",
      "Coefficient of (0, 2): -4.0\n",
      "Coefficient of (0, 0): 1.0\n",
      "[(4, 0), (3, 0), (2, 1), (2, 0), (1, 2), (0, 4), (0, 3), (0, 2), (0, 0)]\n",
      "[4.0, 0.125, 0.375, -4.0, 0.375, 4.0, 0.125, -4.0, 1.0]\n",
      "Now we begin with D = 2\n"
     ]
    }
   ],
   "source": [
    "orders_list, coefficients_list, polynomial, _ = g_D_symbolic_coefficients(x,polynomial)\n",
    "del x\n",
    "x_input= generate_x_input_p2(D,d,L)\n",
    "Lagrangian_coefficient = generate_lag(D,d,L)\n",
    "\n",
    "iteration = 0\n",
    "print(\"Now we begin with D = {}\".format(D))\n",
    "\n",
    "x_mu_D_L_list,x_R_L_list = restore_matrices(s=x_input,d=d,D=D,L=L)\n",
    "x_M_D_L_list = generate_M_d(x_mu_D_L_list,d,D,L)\n",
    "\n",
    "# term_3 is the sum of the penalty term, but without the gamma*, just the sum\n",
    "v_k = term_3(D,L,x_M_D_L_list,x_mu_D_L_list,x_R_L_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_lagrangian_partial = partial(Augmented_Lagrangian, d=d, D=D, L=L, orders_list=orders_list,\n",
    "                            coefficients_list=coefficients_list,\n",
    "                            Lagrangian_coefficient=Lagrangian_coefficient, gamma=gamma)\n",
    "aug_lagrangian_objective_gradient = partial(jac_term1_new,d=d,D=D,L=L,orders_list=orders_list,coefficients_list=coefficients_list)\n",
    "aug_lagrangian_without_obejective_partial = partial(Augmented_Lagrangian_without_objective, d=d, D=D, L=L,\n",
    "                            Lagrangian_coefficient=Lagrangian_coefficient, gamma=gamma)\n",
    "aug_lagrangian_without_objective_partial_gradient = jax.grad(aug_lagrangian_without_obejective_partial)\n",
    "\n",
    "aug_lagrangian_partial_gradient = lambda x:aug_lagrangian_objective_gradient(x)+aug_lagrangian_without_objective_partial_gradient(x)\n",
    "\n",
    "aug_lag = jax.grad(aug_lagrangian_partial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.46666664  0.125      -4.          0.125       4.          0.\n",
      "  0.          0.          0.          0.46666664  0.125      -4.\n",
      "  0.125       4.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.        ]\n",
      "[ 0.46666664  0.125      -4.          0.125       4.          0.\n",
      "  0.          0.          0.          0.46666664  0.125      -4.\n",
      "  0.125       4.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "print(aug_lagrangian_objective_gradient(x_input))\n",
    "print(aug_lag(x_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the function of whole augumented lagrangian\n",
    "aug_lagrangian_partial = partial(Augmented_Lagrangian, d=d, D=D, L=L, orders_list=orders_list,\n",
    "                            coefficients_list=coefficients_list,\n",
    "                            Lagrangian_coefficient=Lagrangian_coefficient, gamma=gamma)\n",
    "\n",
    "# the function of lagrangian term + penalty term\n",
    "aug_lagrangian_without_obejective_partial = partial(Augmented_Lagrangian_without_objective, d=d, D=D, L=L,\n",
    "                            Lagrangian_coefficient=Lagrangian_coefficient, gamma=gamma)\n",
    "\n",
    "# the gradient of the objective term\n",
    "aug_lagrangian_objective_gradient = partial(jac_term1_new,d=d,D=D,L=L,orders_list=orders_list,coefficients_list=coefficients_list)\n",
    "\n",
    "# the gradient of the lagrangian term + penalty term\n",
    "aug_lagrangian_without_objective_partial_gradient = jax.grad(aug_lagrangian_without_obejective_partial)\n",
    "\n",
    "# the gradient of the whole augumented lagrangian\n",
    "aug_lagrangian_partial_gradient = lambda x:aug_lagrangian_objective_gradient(x)+aug_lagrangian_without_objective_partial_gradient(x)\n",
    "\n",
    "print(\"-\"*40)\n",
    "\n",
    "# the minimize function\n",
    "# Can adjust the parameter in the options\n",
    "result = minimize(aug_lagrangian_partial, x0=x_input,\n",
    "                method='L-BFGS-B',\n",
    "                jac=aug_lagrangian_partial_gradient,\n",
    "                options={\n",
    "                    'gtol': gtol,             # Stopping criterion (relative gradient)\n",
    "                    'ftol': ftol,             # Stopping criterion (absolute value)\n",
    "                    'maxcor': maxcor,             # The order of the approximation Hessian\n",
    "                })\n",
    "\n",
    "\n",
    "print(\"This is {} iteration of LBFGS\".format(iteration))\n",
    "print(\"Minimum value of the Augmented Lagrangian function:\", result.fun)\n",
    "print(\"Was the optimization successful?\", result.success)\n",
    "print(\"Number of iterations:\", result.nit)\n",
    "print(result.message)\n",
    "\n",
    "x_input = result.x\n",
    "# We use the update rule in the Samuel Burer paper\n",
    "\n",
    "Lagrangian_coefficient,gamma,v_k = update_everything(x_input,gamma,Lagrangian_coefficient,v_k,d,D,L)\n",
    "\n",
    "# Calculate the x_min\n",
    "x_mu_D_L_list,_= restore_matrices(x_input,d,D,L)\n",
    "x_M_D_L_list = generate_M_d(x_mu_D_L_list,d,D,L)\n",
    "l_product_list = []\n",
    "for l in range(L):\n",
    "    moment_product = 1\n",
    "    for i in range(D):\n",
    "        moment_product *= x_M_D_L_list[i][l][0,0]\n",
    "    l_product_list.append(moment_product)\n",
    "max_index = l_product_list.index(max(l_product_list))\n",
    "x_final= np.array([x_mu_D_L_list[i][max_index][1]/l_product_list[max_index] for i in range(D)])\n",
    "value_final = polynomial(*x_final)\n",
    "# relative_error = abs((value_final-target_value)/ (target_value+1e-10))\n",
    "print(\"current x_min is {}\".format(x_final))\n",
    "# print(\"current relative error regarding polynomial value is {}\".format(relative_error))\n",
    "print(\"current relative error regarding polynomial value is {}\".format(value_final))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
